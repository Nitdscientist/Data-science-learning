{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment-19\n",
        "\n",
        "## Tensorflow with tensorBoard\n",
        "\n",
        "### Name- NITESH KUMAR Batch-4"
      ],
      "metadata": {
        "id": "7gupTi8hckEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1 Write a program for digits recognition using tensorflow."
      ],
      "metadata": {
        "id": "uQuNx1U0cthp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer:-"
      ],
      "metadata": {
        "id": "Yop7glTq7JMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "szOrFGp_dRl-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKEN-r6EdZFN",
        "outputId": "5ed79a99-2a81-4df9-adaa-8e259536c15c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 input image\n",
        "    layers.Dense(128, activation='relu'),   # Fully connected layer with 128 units and ReLU activation\n",
        "    layers.Dropout(0.2),                   # Dropout layer to reduce overfitting\n",
        "    layers.Dense(10)                       # Output layer with 10 units (one for each digit)\n",
        "])"
      ],
      "metadata": {
        "id": "MYL_9X5ydhHD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vpBNL24sdukj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujZiwboydgM1",
        "outputId": "4e659fd4-eb1c-48ba-cda7-a6829cb6e27d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 2ms/step - loss: 0.2913 - accuracy: 0.9155\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1407 - accuracy: 0.9570\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1061 - accuracy: 0.9688\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0863 - accuracy: 0.9737\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0739 - accuracy: 0.9765\n",
            "313/313 - 1s - loss: 0.0741 - accuracy: 0.9754 - 974ms/epoch - 3ms/step\n",
            "Test accuracy: 0.9753999710083008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAGP5xB03H9l",
        "outputId": "6c915149-d00d-4114-c7a9-307a15537515"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDe_nm0dc198",
        "outputId": "aa338ede-80b2-4c86-a970-09fa7681872e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.5943806e+00, -6.9253397e+00,  1.4675741e+00, ...,\n",
              "         1.0770251e+01, -1.4741257e-02, -1.5139085e-01],\n",
              "       [-4.2618284e+00,  3.1382291e+00,  1.2905441e+01, ...,\n",
              "        -1.4095303e+01, -6.0870245e-02, -1.5494180e+01],\n",
              "       [-8.3419094e+00,  7.1777129e+00, -3.4973791e+00, ...,\n",
              "        -7.3878127e-01, -1.4003062e+00, -6.5365696e+00],\n",
              "       ...,\n",
              "       [-1.3769434e+01, -5.8010468e+00, -1.1303710e+01, ...,\n",
              "        -1.2840583e+00,  6.2437052e-01,  3.0174584e+00],\n",
              "       [-1.5336677e+00, -9.4956284e+00, -9.9884853e+00, ...,\n",
              "        -6.2027130e+00,  4.6420016e+00, -6.8944750e+00],\n",
              "       [-4.1122851e+00, -1.4771558e+01, -1.5290191e+00, ...,\n",
              "        -9.8119001e+00, -6.7887726e+00, -5.9951816e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAhRz2omccaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What are Activation Functions? Give Examples and Explain.\n",
        "## 1. Explain Higerorder Tensor with the help of example."
      ],
      "metadata": {
        "id": "QY0ydgVxcw-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer:-"
      ],
      "metadata": {
        "id": "ouh3qUG57RS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Functions:\n",
        "Activation functions are a crucial component in artificial neural networks. They introduce non-linearity into the network, allowing it to learn complex relationships and patterns in the data. These functions determine whether a neuron should be activated or not, influencing the information flow through the network. Here are some common activation functions along with examples and explanations:\n",
        "\n",
        "#### 1. Sigmoid Function (Logistic):\n",
        "\n",
        "Formula: f(x) = 1 / (1 + e^(-x))\n",
        "Output Range: (0, 1)\n",
        "S-shaped curve, used historically but has vanishing gradient problems for deep networks.\n",
        "Example use case: Binary classification problems.\n",
        "\n",
        "#### 2. Hyperbolic Tangent (Tanh):\n",
        "\n",
        "Formula: f(x) = (e^x - e^(-x)) / (e^x + e^(-x))\n",
        "Output Range: (-1, 1)\n",
        "Similar to the sigmoid but centered around zero, helps alleviate vanishing gradient issues.\n",
        "Example use case: Hidden layers in neural networks.\n",
        "\n",
        "#### 3. Rectified Linear Unit (ReLU):\n",
        "\n",
        "Formula: f(x) = max(0, x)\n",
        "Output Range: [0, ∞)\n",
        "Simple and computationally efficient, widely used for hidden layers.\n",
        "Example use case: Convolutional Neural Networks (CNNs) and deep neural networks.\n",
        "\n",
        "#### 4. Leaky ReLU:\n",
        "\n",
        "Formula: f(x) = x if x > 0 else a * x (where 'a' is a small positive value, e.g., 0.01)\n",
        "Output Range: (-∞, ∞)\n",
        "Addresses the \"dying ReLU\" problem by allowing a small gradient for negative inputs.\n",
        "Example use case: Hidden layers to mitigate dead neurons.\n",
        "\n",
        "#### 5. Parametric ReLU (PReLU):\n",
        "\n",
        "Formula: f(x) = x if x > 0 else a * x (where 'a' is learned from data)\n",
        "Output Range: (-∞, ∞)\n",
        "Similar to Leaky ReLU, but the slope for negative values is learned during training.\n",
        "Example use case: Improving ReLU variants.\n",
        "\n",
        "\n",
        "## Higher-Order Tensor with Example:\n",
        "In the context of TensorFlow and other deep learning libraries, a tensor is a multi-dimensional array. A higher-order tensor is a tensor with more than two dimensions. Here's an example to illustrate a higher-order tensor:\n",
        "\n",
        "Let's say we have an RGB image. Each pixel in the image has three color channels: Red, Green, and Blue. If the image has a resolution of 100x100, you can represent it as a 3D tensor with the shape (100, 100, 3).\n",
        "\n",
        "In this example, the higher-order tensor is a 3D tensor because it has three dimensions:\n",
        "\n",
        "The first dimension represents the height of the image (100 pixels).\n",
        "The second dimension represents the width of the image (100 pixels).\n",
        "The third dimension represents the color channels (Red, Green, and Blue).\n",
        "\n",
        "We can generalize this concept to even higher-order tensors for more complex data structures. For instance, in video data, you might have a 4D tensor representing (frames, height, width, channels), and in natural language processing, we might have tensors representing word embeddings with dimensions for (batch size, sequence length, word vector dimensions). Higher-order tensors are used in various deep learning applications to handle data with multiple dimensions and complex structures."
      ],
      "metadata": {
        "id": "eompzaI36I7f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUgACliHcglA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}